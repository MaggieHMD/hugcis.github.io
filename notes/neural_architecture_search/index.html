<!DOCTYPE html>
<html lang="en-us">
<head>


<meta charset="utf-8">
<meta name="viewport" content=
"width=device-width,initial-scale=1.0,minimum-scale=1">
<title>Neural architecture search - Hugo Cisneros - Personal
page</title>
<meta property="og:title" content=
"Neural architecture search - Hugo Cisneros - Personal page">
<meta property="og:type" content="article">
<meta property="og:image" content="/img/main.jpeg">
<meta property="og:url" content=
"https://hugocisneros.com/notes/neural_architecture_search/">
<meta property="og:description" content=
"Notes about Neural architecture search">
<meta name="Description" property="description" content=
"Notes about Neural architecture search">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@cisne_hug">
<meta name="twitter:creator" content="@cisne_hug">
<link rel="stylesheet" href=
"https://hugocisneros.com/css/main.min.09ba75009ac37877191541f27444e8270145acc4b2d3d9426f22f0fb43420b6e.css"
media="all" type="text/css">
<link rel="apple-touch-icon" sizes="180x180" href=
"/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href=
"/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href=
"/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color=
"#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
<link rel="webmention" href=
"https://webmention.io/hugocisneros.com/webmention">
<link rel="pingback" href=
"https://webmention.io/hugocisneros.com/xmlrpc">
</head>
<body>
<div class="wrapper">
<header class="header">
<nav class="nav">
<div class="nav-main"><a href="https://hugocisneros.com/" class=
"nav-title">Hugo Cisneros - Personal page</a></div>
<ul class="nav-links">
<li><a href="/about/">About</a></li>
<li><a href="/blog/">Blog</a></li>
<li><a href="/other/">Other</a></li>
<li><a href="/resume/cv.pdf">Resume</a></li>
</ul>
</nav>
</header>
<main class="content" role="main">
<article class="article h-entry" itemprop="mainEntity" itemscope
itemtype="http://schema.org/BlogPosting">
<div class="single-note note-container">
<h1 class="article-title p-name" itemprop="name">Neural
architecture search</h1>
<div class="article-content e-content p-name" itemprop=
"articleBody">
<dl>
<dt>tags</dt>
<dd><a href="/notes/search/">Search</a>, <a href=
"/notes/neural_networks/">Neural networks</a></dd>
</dl>
<p>Neural architecture search (NAS) is a method for finding
<a href="/notes/neural_networks/">neural networks</a>
architectures. It is usually based on three main components:</p>
<dl>
<dt>Search space</dt>
<dd>Type of network that can be built.</dd>
<dt>Search strategy</dt>
<dd>The approach for exploring the space.</dd>
<dt>Performance estimation strategy</dt>
<dd>The way the performance of a constructed neural network is
evaluated (without actually building it or training/running
it).</dd>
</dl>
<h2 id=
"reinforcement-learning--reinforcement-learning-dot-md--based-nas">
<a href="/notes/reinforcement_learning/">Reinforcement
learning</a>-based NAS</h2>
<p>The original idea was called Neural architecture search and is
based on the use of a RNN as a controller and generator of
architectures. The search-space is pre-defined and explored in a
rigid way. <a id="a283bf303d6337f87e8d4efeb5df8b7d" href=
"#zophNeuralArchitectureSearch2017">(Zoph & Le, 2017)</a>.</p>
<p>The process of generating architectures from the first article
was extremely lengthy and replaced later by a more constrained
search. <a id="dbba5c99b9c751b32b6e58174c2800ab" href=
"#zophLearningTransferableArchitectures2018">(Zoph et al.,
2018)</a>.</p>
<p>Recent ideas include the use of parameter sharing across
architectures because the main bottleneck of previous techniques
was essentially in the training of each child model. This results
in significant speedup of RL-based NAS. <a id=
"fec97e39a1f34b9aa84ee30e76ef1fd0" href=
"#phamEfficientNeuralArchitecture2018">(Pham et al., 2018)</a></p>
<h2 id="neuroevolution">Neuroevolution</h2>
<p>This field is more focused on <a href=
"/notes/evolution/">evolution</a> neural network through
evolutionary methods such as e.g <a href=
"/notes/genetic_algorithm/">genetic algorithms</a>. One of the main
work that made that field popular is <a href=
"/notes/neat/">NEAT</a> <a id="9af7b8b9640ea8d7a87a4d4e9ed0b9c5"
href="#stanleyEvolvingNeuralNetworks2002">(Stanley & Miikkulainen,
2002)</a>.</p>
<h1 id="bibliography">Bibliography</h1>
<p><a id="zophNeuralArchitectureSearch2017" target="_blank">Zoph,
B., & Le, Q. V., <em>Neural Architecture Search with Reinforcement
Learning</em>, arXiv:1611.01578 [cs], <em>()</em>, (2017).</a>
<a href="#a283bf303d6337f87e8d4efeb5df8b7d">↩</a></p>
<p><a id="zophLearningTransferableArchitectures2018" target=
"_blank">Zoph, B., Vasudevan, V., Shlens, J., & Le, Q. V.,
<em>Learning Transferable Architectures for Scalable Image
Recognition</em>, arXiv:1707.07012 [cs, stat], <em>()</em>,
(2018).</a> <a href="#dbba5c99b9c751b32b6e58174c2800ab">↩</a></p>
<p><a id="phamEfficientNeuralArchitecture2018" target=
"_blank">Pham, H., Guan, M. Y., Zoph, B., Le, Q. V., & Dean, J.,
<em>Efficient Neural Architecture Search via Parameter
Sharing</em>, arXiv:1802.03268 [cs, stat], <em>()</em>, (2018).</a>
<a href="#fec97e39a1f34b9aa84ee30e76ef1fd0">↩</a></p>
<p><a id="stanleyEvolvingNeuralNetworks2002" target=
"_blank">Stanley, K. O., & Miikkulainen, R., <em>Evolving Neural
Networks through Augmenting Topologies</em>, Evolutionary
Computation, <em>10(2)</em>, 99–127 (2002).</a> <a href=
"http://dx.doi.org/10.1162/106365602320169811">http://dx.doi.org/10.1162/106365602320169811</a>
<a href="#9af7b8b9640ea8d7a87a4d4e9ed0b9c5">↩</a></p>
<h2 id="backlinks">Backlinks</h2>
<ul>
<li><a href="/notes/zophneuralarchitecturesearch2017/">Notes on:
Zoph, B., & Le, Q. V. (2017): Neural Architecture Search with
Reinforcement Learning</a></li>
<li><a href="/notes/stanleyevolvingneuralnetworks2002/">Notes on:
Stanley, K. O., & Miikkulainen, R. (2002): Evolving Neural Networks
through Augmenting Topologies</a></li>
<li><a href=
"/notes/floreanoneuroevolutionarchitectureslearning2008/">Notes on:
Floreano, D., Dürr, P., & Mattiussi, C. (2008): Neuroevolution:
from architectures to learning</a></li>
<li><a href=
"/notes/zophlearningtransferablearchitectures2018/">Notes on: Zoph,
B., Vasudevan, V., Shlens, J., & Le, Q. V. (2018): Learning
Transferable Architectures for Scalable Image Recognition</a></li>
</ul>
</div>
<div class="note-footer">Last changed <a class="u-url" href=
"https://hugocisneros.com/notes/neural_architecture_search/"><time itemprop="datePublished"
class="dt-published" datetime=
"0001-01-01T00:00:00Z">01/01/0001</time></a> | authored by <a href=
"https://hugocisneros.com/" rel="author" class="p-author h-card"
itemprop="author" itemscope itemtype=
"http://schema.org/Person"><span itemprop="name">Hugo
Cisneros</span></a></div>
</div>
</article>
<br>
<a href="/notes#neural_architecture_search"><b>← Back to
Notes</b></a>
<hr></main>
<footer class="footer">
<ul class="footer-links">
<li><a href="/blog/index.xml" type="application/rss+xml" target=
"_blank">Blog RSS feed</a></li>
<li><a href=
"https://github.com/hugcis/natrium-custom">Code</a></li>
</ul>
</footer>
</div>
<script>
 MathJax = {
     tex: {
         inlineMath: [['$','$'], ['\\(', '\\)']],
         tags: 'ams'
     }
 };
</script> 
<script type="text/javascript" rel="preconnect" id="MathJax-script"
async src=
"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<script>

btn.addEventListener("click", function() {
    if (prefersDarkScheme.matches) {
    document.body.classList.toggle("light-theme");
    } else {
    document.body.classList.toggle("dark-theme");
    }
});
</script>
</body>
</html>
